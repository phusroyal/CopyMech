{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the dataset from disk\n",
    "num_samples = 1000\n",
    "subset = load_from_disk(\"/home/longnhat/workspace_phu/CopyMech/english_insertions\")\n",
    "prompt_list = []\n",
    "\n",
    "base_sents = subset['train']['base_sentence'][:num_samples]\n",
    "phrases = subset['train']['phrase'][:num_samples]\n",
    "edited_sents = subset['train']['edited_sentence'][:num_samples]\n",
    "\n",
    "import gc\n",
    "del subset\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_required_spaces(seq: str) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if the sequence has an occurrence of 'is' or 'are'\n",
    "    that is preceded (anywhere earlier in the sequence) by at least 6 tokens that are exactly 'space'.\n",
    "    \n",
    "    Examples:\n",
    "      'There space space space space space oh space is a cat.' -> True\n",
    "      'There space are many cats.' -> False\n",
    "      'There is a cat.' -> False\n",
    "      'There space space space space space space is a cat.' -> True\n",
    "      'There spaces are many cats.' -> False\n",
    "    \"\"\"\n",
    "    tokens = seq.split()\n",
    "    # check if sentence only has 1 is or are\n",
    "    if tokens.count(\"is\") + tokens.count(\"are\") != 1:\n",
    "        return False\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in {\"is\", \"are\"}:\n",
    "            # Count how many tokens before this occurrence are exactly \"space\"\n",
    "            if len(tokens[:i]) >= 6:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# select sentences that has 'is' or 'are' in edited sentence and have at least 6 spaces before that word\n",
    "prompt_list = []\n",
    "for base_sent, phrase, edited_sent in zip(base_sents, phrases, edited_sents):\n",
    "    if len(prompt_list) == 100:\n",
    "        break\n",
    "    if has_required_spaces(edited_sent):\n",
    "        prompt_list.append((base_sent, phrase, edited_sent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['On', 'the', 'left', 'there', 'is', 'a', 'cotton', 'plant', 'and', 'to', 'the', 'right', 'wheat', 'borders', 'the', 'coat', 'of', 'arms', ',', 'cotton', 'and', 'wheat', 'are', 'the', 'two', 'major', 'agricultural', 'products', 'of', 'the', 'country', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'On the left there is a cotton plant and to the right wheat borders the coat of arms , cotton and wheat are the two major agricultural products of the country .\\n'\n",
    "has_required_spaces(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs_length(a_tokens, b_tokens):\n",
    "    \"\"\"\n",
    "    Returns the length of the Longest Common Subsequence (LCS)\n",
    "    between two lists of tokens a_tokens, b_tokens.\n",
    "    \"\"\"\n",
    "    len_a = len(a_tokens)\n",
    "    len_b = len(b_tokens)\n",
    "    # dp[i][j] will hold LCS length of a_tokens[:i], b_tokens[:j]\n",
    "    dp = [[0]*(len_b+1) for _ in range(len_a+1)]\n",
    "\n",
    "    for i in range(1, len_a+1):\n",
    "        for j in range(1, len_b+1):\n",
    "            if a_tokens[i-1] == b_tokens[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
    "    return dp[len_a][len_b]\n",
    "\n",
    "def compute_rouge_l(reference_str: str, candidate_str: str) -> float:\n",
    "    \"\"\"\n",
    "    Computes ROUGE-L (F-measure) for reference vs. candidate.\n",
    "    Returns a value between 0~1.\n",
    "    \"\"\"\n",
    "    ref_tokens = reference_str.split()\n",
    "    cand_tokens = candidate_str.split()\n",
    "\n",
    "    lcs = lcs_length(ref_tokens, cand_tokens)\n",
    "    m = len(ref_tokens)\n",
    "    n = len(cand_tokens)\n",
    "\n",
    "    if m == 0 or n == 0:\n",
    "        return 0.0\n",
    "\n",
    "    recall = lcs / m\n",
    "    precision = lcs / n\n",
    "    if recall+precision == 0:\n",
    "        return 0.0\n",
    "    f_score = 2 * recall * precision / (recall + precision)\n",
    "    return f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline('text-generation', model=\"Qwen/Qwen2.5-3B\", max_new_tokens = 50, device='cuda:0', return_full_text=False)\n",
    "tokenizer = generator.tokenizer\n",
    "\n",
    "a = \"The cat are sitting on the mat.\"\n",
    "prompt = f\"There is grammatical error in the following text: '{a}'. The correct text is:\"\n",
    "pred = generator(prompt)[0]['generated_text']\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprompt_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "prompt_list[11][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('his father durint ww2 is a student', 'his father durint ww2')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_preprocess(text):\n",
    "    \"\"\"Given a text, replace ' is ' by ' are ', and vice versa. Return the corrupted text, and the text until the first is/are.\"\"\"\n",
    "    text = text.strip()\n",
    "    if ' is ' in text:\n",
    "        corrupted_text = text.replace(' is ', ' are ', 1)\n",
    "    elif ' are ' in text:\n",
    "        corrupted_text = text.replace(' are ', ' is ', 1)\n",
    "    \n",
    "    # find position of first is/are and return text before that\n",
    "    first_is = text.find(' is ')\n",
    "    first_are = text.find(' are ')\n",
    "    print(first_is, first_are)\n",
    "    if first_is == -1 and first_are == -1:\n",
    "        return None\n",
    "    elif first_is == -1:\n",
    "        return corrupted_text, text[:first_are]\n",
    "    elif first_are == -1:\n",
    "        return corrupted_text, text[:first_is]\n",
    "    \n",
    "    return corrupted_text, text[:min(first_is, first_are)]\n",
    "\n",
    "text_preprocess('his father durint ww2 are a student')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \"There are exceptions to the definition above, and many solid chemical materials familiar on Earth (for example, many silicate minerals) do not have simple formulas in which various elements that are chemically bonded to each other stand in exact and fixed ratios.\"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"'There are exceptions to the definition above , and many solid chemical materials familiar on Earth ( for example many silicate minerals ) do not have simple formulas in which cool various elements that is chemically bonded to each other stand in exact and fixed ratios .\\n\"\n",
    "prompt = f\"Please fix grammar of the following text: '{a}'. The correct text is:\"\n",
    "# prompt = f\"There is grammatical error in the following text: '{a}'. Please fix the text:\"\n",
    "pred = generator(prompt)[0]['generated_text']\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('stabilityai/stablelm-2-1_6b-chat')\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'stabilityai/stablelm-2-1_6b-chat',\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "a = \"He were a student.\"\n",
    "prompt = f\"There is grammatical error in the following text: '{a}'. The correct text is:\"\n",
    "\n",
    "prompt = [{'role': 'user', 'content': prompt}]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    prompt,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "tokens = model.generate(\n",
    "    inputs.to(model.device),\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.7,\n",
    "    do_sample=True\n",
    ")\n",
    "output = tokenizer.decode(tokens[:, inputs.shape[-1]:][0], skip_special_tokens=False)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "\n",
    "# load model and tokenizer\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HookedTransformer.from_pretrained(\"stablelm-2-1_6b-chat\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('stabilityai/stablelm-2-1_6b-chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:100257 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" What is He's occupation?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Rewrite the below sentence with correct grammar. \n",
    "Context : He are a student.\n",
    "Output:\"\"\"\n",
    "pred = generator(prompt)[0]['generated_text']\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:100257 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" 'He were a student.'.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"He were a student.\"\n",
    "prompt = f\"There is grammatical error in the following text: '{a}'. The correct text is:\"\n",
    "pred = generator(prompt)[0]['generated_text']\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" 'In the meanwhile, Dadaji lost his mother and took to living with his maternal uncle Narayan Dhurmaji.'\\n\\nInsert this phrase of 'In the meanwhile,' in to this sentence of 'Dadaji lost his mother and\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline('text-generation', model=\"facebook/opt-2.7b\", max_new_tokens = 50, device='cuda:0', return_full_text=False)\n",
    "tokenizer = generator.tokenizer\n",
    "\n",
    "needed_samples = []\n",
    "for base, phrase, edited in tqdm(zip(base_sents, phrases, edited_sents)):\n",
    "    prompt = f\"Insert this phrase of '{phrase}' in to this sentence of '{base}'. The inserted sentence is:\"\n",
    "    pred = generator(prompt)[0]['generated_text']\n",
    "\n",
    "    encoded_edited = tokenizer(edited, return_tensors='pt').input_ids\n",
    "    encoded_pred = tokenizer(pred, return_tensors='pt').input_ids\n",
    "\n",
    "    # truncate the pred according to the length of the y + 2\n",
    "    encoded_pred = encoded_pred[:, :encoded_edited.shape[1]+1]\n",
    "    \n",
    "    # decode the tokens\n",
    "    pred = tokenizer.decode(encoded_pred[0], skip_special_tokens=True)\n",
    "\n",
    "    # compute the rouge-l score\n",
    "    rouge_l_score = compute_rouge_l(reference_str=edited, candidate_str=pred)\n",
    "    \n",
    "    if rouge_l_score > 0.8: \n",
    "        needed_samples.append({'base': base, 'phrase': phrase, 'edited': edited, 'pred': pred, 'rouge_l': rouge_l_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icl_mi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
