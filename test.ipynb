{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test copy small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Set up the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the GPT-2 XL tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-xl')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Enable outputting hidden states\n",
    "model.config.output_hidden_states = True\n",
    "\n",
    "# Create a long text with a repeated span for summarization\n",
    "text = (\n",
    "    \"Once upon a time in a land far, far away, there lived a wise old king. \"\n",
    "    \"He ruled his kingdom with justice and kindness, and all his subjects loved him dearly. \"\n",
    "    \"One day, a young traveler arrived at the kingdom. He had heard tales of the king's wisdom and sought his counsel. \"\n",
    "    \"The wise old king welcomed the traveler warmly. \"\n",
    "    \"He ruled his kingdom with justice and kindness, and all his subjects loved him dearly. \"  # Repeated span\n",
    "    \"The traveler was amazed by the prosperity and happiness of the people. \"\n",
    "    \"He decided to stay and learn from the king. \"\n",
    "    \"Years passed, and the traveler became a trusted advisor to the king. \"\n",
    ")\n",
    "\n",
    "# Tokenize the text\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt').to(device)\n",
    "\n",
    "# Get the number of tokens\n",
    "num_tokens = input_ids.shape[1]\n",
    "\n",
    "# Generate position IDs\n",
    "position_ids = torch.arange(num_tokens, dtype=torch.long, device=device)\n",
    "position_ids = position_ids.unsqueeze(0)\n",
    "\n",
    "# Generate attention mask\n",
    "attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "# Get the token embeddings and positional embeddings\n",
    "with torch.no_grad():\n",
    "    token_embeddings = model.transformer.wte(input_ids)\n",
    "    positional_embeddings = model.transformer.wpe(position_ids)\n",
    "    input_embeddings = token_embeddings + positional_embeddings\n",
    "\n",
    "# Convert input_ids to list for easy manipulation\n",
    "tokens = input_ids[0].tolist()\n",
    "\n",
    "# Decode tokens for verification\n",
    "decoded_tokens = [tokenizer.decode([token]) for token in tokens]\n",
    "\n",
    "# Print tokens and their decoded forms\n",
    "print(\"Tokens and their decoded forms:\")\n",
    "for i, (token_id, token_text) in enumerate(zip(tokens, decoded_tokens)):\n",
    "    print(f\"Token {i}: {token_id} -> {repr(token_text)}\")\n",
    "\n",
    "# Manually identify the positions of the repeated spans\n",
    "# First occurrence\n",
    "t1_start = 19\n",
    "t1_end = 34  # Adjusted to exclude the period if necessary\n",
    "\n",
    "# Second occurrence\n",
    "t2_start = 71\n",
    "t2_end = 86  # Adjusted to exclude the period if necessary\n",
    "\n",
    "# Verify that the tokens in both spans are the same\n",
    "print(\"\\nFirst occurrence tokens:\")\n",
    "for i in range(t1_start, t1_end + 1):\n",
    "    print(f\"Token {i}: {tokens[i]} -> {repr(decoded_tokens[i])}\")\n",
    "\n",
    "print(\"\\nSecond occurrence tokens:\")\n",
    "for i in range(t2_start, t2_end + 1):\n",
    "    print(f\"Token {i}: {tokens[i]} -> {repr(decoded_tokens[i])}\")\n",
    "\n",
    "# Extract embeddings for the first occurrence\n",
    "embeds_t1 = input_embeddings[:, t1_start:t1_end + 1, :]\n",
    "pos_embeds_t1 = positional_embeddings[:, t1_start:t1_end + 1, :]\n",
    "\n",
    "# Derotate the embeddings\n",
    "embeds_t1_derotated = embeds_t1 - pos_embeds_t1\n",
    "\n",
    "# Get positional embeddings for the second occurrence\n",
    "pos_embeds_t2 = positional_embeddings[:, t2_start:t2_end + 1, :]\n",
    "\n",
    "# Rerotate the embeddings to the new positions\n",
    "embeds_t1_adjusted = embeds_t1_derotated + pos_embeds_t2\n",
    "\n",
    "# Replace the embeddings of the second occurrence with the adjusted embeddings\n",
    "input_embeddings_adjusted = input_embeddings.clone()\n",
    "input_embeddings_adjusted[:, t2_start:t2_end + 1, :] = embeds_t1_adjusted\n",
    "\n",
    "# Pass the original embeddings through the model\n",
    "with torch.no_grad():\n",
    "    outputs_original = model(inputs_embeds=input_embeddings, attention_mask=attention_mask, position_ids=position_ids)\n",
    "    logits_original = outputs_original.logits\n",
    "\n",
    "# Pass the adjusted embeddings through the model\n",
    "with torch.no_grad():\n",
    "    outputs_adjusted = model(inputs_embeds=input_embeddings_adjusted, attention_mask=attention_mask, position_ids=position_ids)\n",
    "    logits_adjusted = outputs_adjusted.logits\n",
    "\n",
    "# Compare the logits of the token following the repeated span\n",
    "next_token_position = t2_end + 1\n",
    "logits_original_next = logits_original[:, next_token_position, :]\n",
    "logits_adjusted_next = logits_adjusted[:, next_token_position, :]\n",
    "\n",
    "# Get the top predicted tokens\n",
    "top_k = 5\n",
    "prob_original = torch.softmax(logits_original_next, dim=-1)\n",
    "prob_adjusted = torch.softmax(logits_adjusted_next, dim=-1)\n",
    "\n",
    "top_tokens_original = torch.topk(prob_original, top_k, dim=-1)\n",
    "top_tokens_adjusted = torch.topk(prob_adjusted, top_k, dim=-1)\n",
    "\n",
    "print(\"\\nTop predictions after the original repeated span:\")\n",
    "for idx in top_tokens_original.indices[0]:\n",
    "    print(tokenizer.decode([idx.item()]))\n",
    "\n",
    "print(\"\\nTop predictions after the adjusted repeated span:\")\n",
    "for idx in top_tokens_adjusted.indices[0]:\n",
    "    print(tokenizer.decode([idx.item()]))\n",
    "\n",
    "# Check if the predictions are the same\n",
    "are_predictions_same = torch.equal(top_tokens_original.indices, top_tokens_adjusted.indices)\n",
    "print(f\"\\nAre the top {top_k} predictions the same after adjustment? {are_predictions_same}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sublist found from index 1 to 3\n"
     ]
    }
   ],
   "source": [
    "def find_sublist(a, b):\n",
    "    \"\"\"\n",
    "    Finds the start and end indices of list a within list b.\n",
    "\n",
    "    Args:\n",
    "        a (list): The sublist to find.\n",
    "        b (list): The list to search in.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple (start_index, end_index) if sublist is found.\n",
    "        None: If the sublist is not found.\n",
    "    \"\"\"\n",
    "    len_a = len(a)\n",
    "    len_b = len(b)\n",
    "\n",
    "    for i in range(len_b - len_a + 1):\n",
    "        if b[i:i+len_a] == a:\n",
    "            return i, i + len_a - 1\n",
    "    return None\n",
    "a = [2, 3, 4]\n",
    "b = [1, 2, 3, 4, 5]\n",
    "\n",
    "result = find_sublist(a, b)\n",
    "if result:\n",
    "    print(f\"Sublist found from index {result[0]} to {result[1]}\")\n",
    "else:\n",
    "    print(\"Sublist not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The second occurrence of list_a starts at index 1.\n"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def find_second_occurrence_fuzzy(list_a, list_b, min_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Finds the starting index of the second occurrence of list_a in list_b\n",
    "    using approximate matching.\n",
    "\n",
    "    Parameters:\n",
    "    list_a (list): The sublist to find.\n",
    "    list_b (list): The list in which to search for the sublist.\n",
    "    min_ratio (float): Minimum similarity ratio to consider a match (0 to 1).\n",
    "\n",
    "    Returns:\n",
    "    int: The starting index of the second occurrence of list_a in list_b.\n",
    "         Returns -1 if the second occurrence is not found.\n",
    "    \"\"\"\n",
    "    len_a = len(list_a)\n",
    "    len_b = len(list_b)\n",
    "    occurrences = []\n",
    "\n",
    "    for i in range(len_b - len_a + 1):\n",
    "        # Compare slices using SequenceMatcher\n",
    "        s = SequenceMatcher(None, list_a, list_b[i:i + len_a])\n",
    "        ratio = s.ratio()\n",
    "\n",
    "        if ratio >= min_ratio:\n",
    "            occurrences.append(i)\n",
    "            if len(occurrences) == 2:\n",
    "                return occurrences[1]  # Return the index of the second occurrence\n",
    "\n",
    "    # If the second occurrence is not found\n",
    "    return -1\n",
    "\n",
    "# Example usage with your lists:\n",
    "list_a = ['Dad', 'aji', ' lost', ' his', ' mother', ' and', ' took', ' to', ' living', ' with', ' his', ' maternal', ' uncle', ' Nar', 'ayan', ' Dh', 'ur', 'm', 'aji', ' ', '.']\n",
    "list_b = ['Base', ' sentence', ':', ' Dad', 'aji', ' lost', ' his', ' mother', ' and', ' took', ' to', ' living', ' with', ' his', ' maternal', ' uncle', ' Nar', 'ayan', ' Dh', 'ur', 'm', 'aji', ' ', '.', '\\n', 'Ph', 'rase', ' to', ' inserted', ':', ' In', ' the', ' meanwhile', ' ', ',', '\\n', 'Edited', ' sentence', ':', ' In', ' the', ' meanwhile', ' ', ',', ' Dad', 'aji', ' lost', ' his', ' mother', ' and', ' took', ' to', ' living', ' with', ' his', ' maternal', ' uncle', ' Nar', 'ayan', ' Dh', 'ur', 'm', 'aji', ' ', '.']\n",
    "\n",
    "index = find_second_occurrence_fuzzy(list_a, list_b)\n",
    "\n",
    "if index != -1:\n",
    "    print(f\"The second occurrence of list_a starts at index {index}.\")\n",
    "else:\n",
    "    print(\"The sublist does not occur twice in list_b.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The second occurrence of list_a starts at index 44.\n"
     ]
    }
   ],
   "source": [
    "def tokens_match(token_a, token_b):\n",
    "    # Custom comparison function\n",
    "    return token_a.strip() == token_b.strip()\n",
    "\n",
    "def find_second_occurrence_custom(list_a, list_b):\n",
    "    len_a = len(list_a)\n",
    "    len_b = len(list_b)\n",
    "    occurrences = []\n",
    "\n",
    "    for i in range(len_b - len_a + 1):\n",
    "        match = True\n",
    "        for j in range(len_a):\n",
    "            if not tokens_match(list_a[j], list_b[i + j]):\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            occurrences.append(i)\n",
    "            if len(occurrences) == 2:\n",
    "                return occurrences[1]\n",
    "    return -1\n",
    "\n",
    "# Example usage:\n",
    "index = find_second_occurrence_custom(list_a, list_b)\n",
    "print(f\"The second occurrence of list_a starts at index {index}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Dad'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_b[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List A: ['Dad', 'aji', ' lost', ' his', ' mother', ' and', ' took', ' to', ' living', ' with', ' his', ' maternal', ' uncle', ' Nar', 'ayan', ' Dh', 'ur', 'm', 'aji', ' ', '.']\n",
      "List B: ['Base', ' sentence', ':', ' Dad', 'aji', ' lost', ' his', ' mother', ' and', ' took', ' to', ' living', ' with', ' his', ' maternal', ' uncle', ' Nar', 'ayan', ' Dh', 'ur', 'm', 'aji', ' ', '.', '\\n', 'Ph', 'rase', ' to', ' inserted', ':', ' In', ' the', ' meanwhile', ' ', ',', '\\n', 'Edited', ' sentence', ':', ' In', ' the', ' meanwhile', ' ', ',', ' Dad', 'aji', ' lost', ' his', ' mother', ' and', ' took', ' to', ' living', ' with', ' his', ' maternal', ' uncle', ' Nar', 'ayan', ' Dh', 'ur', 'm', 'aji', ' ', '.']\n",
      "Index of the second occurrence: -1\n"
     ]
    }
   ],
   "source": [
    "def find_second_occurrence(list_a, list_b):\n",
    "    # Counter to track occurrences\n",
    "    occurrence_count = 0\n",
    "\n",
    "    # Debugging: Print the lists\n",
    "    print(\"List A:\", list_a)\n",
    "    print(\"List B:\", list_b)\n",
    "\n",
    "    # Iterate through list_b to find all occurrences of list_a\n",
    "    for i in range(len(list_b) - len(list_a) + 1):\n",
    "        # Check if the current slice of list_b matches list_a\n",
    "        if list_b[i:i + len(list_a)] == list_a:\n",
    "            occurrence_count += 1\n",
    "            print(f\"Match found at index {i}, occurrence count: {occurrence_count}\")\n",
    "            if occurrence_count == 2:  # Return index when the second occurrence is found\n",
    "                return i\n",
    "    return -1  # Return -1 if the second occurrence is not found\n",
    "\n",
    "# Example lists\n",
    "list_a = ['Dad', 'aji', ' lost', ' his', ' mother', ' and', ' took', ' to', ' living', ' with', ' his', ' maternal', ' uncle', ' Nar', 'ayan', ' Dh', 'ur', 'm', 'aji', ' ', '.']\n",
    "list_b = ['Base', ' sentence', ':', ' Dad', 'aji', ' lost', ' his', ' mother', ' and', ' took', ' to', ' living', ' with', ' his', ' maternal', ' uncle', ' Nar', 'ayan', ' Dh', 'ur', 'm', 'aji', ' ', '.', '\\n', 'Ph', 'rase', ' to', ' inserted', ':', ' In', ' the', ' meanwhile', ' ', ',', '\\n', 'Edited', ' sentence', ':', ' In', ' the', ' meanwhile', ' ', ',', ' Dad', 'aji', ' lost', ' his', ' mother', ' and', ' took', ' to', ' living', ' with', ' his', ' maternal', ' uncle', ' Nar', 'ayan', ' Dh', 'ur', 'm', 'aji', ' ', '.']\n",
    "\n",
    "# Find the second occurrence\n",
    "second_index = find_second_occurrence(list_a, list_b)\n",
    "\n",
    "print(\"Index of the second occurrence:\", second_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['Dad', 'aji', ' lost', ' his', ' mother', ' and', ' took', ' to', ' living', ' with', ' his', ' maternal', ' uncle', ' Nar', 'ayan', ' Dh', 'ur', 'm', 'aji', ' ', '.']\n",
    "['Base', ' sentence', ':', ' Dad', 'aji', ' lost', ' his', ' mother', ' and', ' took', ' to', ' living', ' with', ' his', ' maternal', ' uncle', ' Nar', 'ayan', ' Dh', 'ur', 'm', 'aji', ' ', '.', '\\n', 'Ph', 'rase', ' to', ' inserted', ':', ' In', ' the', ' meanwhile', ' ', ',', '\\n', 'Edited', ' sentence', ':', ' In', ' the', ' meanwhile', ' ', ',', ' Dad', 'aji', ' lost', ' his', ' mother', ' and', ' took', ' to', ' living', ' with', ' his', ' maternal', ' uncle', ' Nar', 'ayan', ' Dh', 'ur', 'm', 'aji', ' ', '.']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phu.hoang/.conda/envs/copy_mech/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First occurrence tokens:\n",
      "Token 19: 679 -> ' He'\n",
      "Token 20: 8879 -> ' ruled'\n",
      "Token 21: 465 -> ' his'\n",
      "Token 22: 13239 -> ' kingdom'\n",
      "Token 23: 351 -> ' with'\n",
      "Token 24: 5316 -> ' justice'\n",
      "Token 25: 290 -> ' and'\n",
      "Token 26: 23887 -> ' kindness'\n",
      "Token 27: 11 -> ','\n",
      "Token 28: 290 -> ' and'\n",
      "Token 29: 477 -> ' all'\n",
      "Token 30: 465 -> ' his'\n",
      "Token 31: 7481 -> ' subjects'\n",
      "Token 32: 6151 -> ' loved'\n",
      "Token 33: 683 -> ' him'\n",
      "Token 34: 46379 -> ' dearly'\n",
      "\n",
      "Second occurrence tokens:\n",
      "Token 71: 679 -> ' He'\n",
      "Token 72: 8879 -> ' ruled'\n",
      "Token 73: 465 -> ' his'\n",
      "Token 74: 13239 -> ' kingdom'\n",
      "Token 75: 351 -> ' with'\n",
      "Token 76: 5316 -> ' justice'\n",
      "Token 77: 290 -> ' and'\n",
      "Token 78: 23887 -> ' kindness'\n",
      "Token 79: 11 -> ','\n",
      "Token 80: 290 -> ' and'\n",
      "Token 81: 477 -> ' all'\n",
      "Token 82: 465 -> ' his'\n",
      "Token 83: 7481 -> ' subjects'\n",
      "Token 84: 6151 -> ' loved'\n",
      "Token 85: 683 -> ' him'\n",
      "Token 86: 46379 -> ' dearly'\n",
      "\n",
      "Top predictions after the adjusted repeated span:\n",
      " He\n",
      " The\n",
      " But\n",
      " \"\n",
      " They\n",
      "\n",
      "Top predictions after the original repeated span:\n",
      " One\n",
      "\n",
      "\n",
      " He\n",
      "\n",
      "\n",
      "\n",
      " But\n",
      "\n",
      "Are the top 5 predictions the same after adjustment? False\n",
      "\n",
      "Top predictions after the adjusted repeated span:\n",
      " traveler\n",
      " young\n",
      " king\n",
      " two\n",
      " old\n",
      "\n",
      "Top predictions after the original repeated span:\n",
      " traveler\n",
      " young\n",
      " wise\n",
      " king\n",
      " old\n",
      "\n",
      "Are the top 5 predictions the same after adjustment? False\n",
      "\n",
      "Top predictions after the adjusted repeated span:\n",
      " asked\n",
      " told\n",
      " was\n",
      " said\n",
      " then\n",
      "\n",
      "Top predictions after the original repeated span:\n",
      " asked\n",
      " was\n",
      " told\n",
      " left\n",
      " had\n",
      "\n",
      "Are the top 5 predictions the same after adjustment? False\n",
      "\n",
      "Top predictions after the adjusted repeated span:\n",
      " a\n",
      " given\n",
      " told\n",
      " so\n",
      " very\n",
      "\n",
      "Top predictions after the original repeated span:\n",
      " a\n",
      " very\n",
      " kind\n",
      " so\n",
      " young\n",
      "\n",
      "Are the top 5 predictions the same after adjustment? False\n",
      "\n",
      "Top predictions after the adjusted repeated span:\n",
      " at\n",
      " by\n",
      " to\n",
      " and\n",
      ",\n",
      "\n",
      "Top predictions after the original repeated span:\n",
      " at\n",
      " by\n",
      " to\n",
      " and\n",
      ",\n",
      "\n",
      "Are the top 5 predictions the same after adjustment? True\n",
      "\n",
      "Top predictions after the adjusted repeated span:\n",
      " the\n",
      " his\n",
      " how\n",
      " what\n",
      " all\n",
      "\n",
      "Top predictions after the original repeated span:\n",
      " the\n",
      " his\n",
      " how\n",
      " all\n",
      " what\n",
      "\n",
      "Are the top 5 predictions the same after adjustment? False\n",
      "\n",
      "Top predictions after the adjusted repeated span:\n",
      " king\n",
      " old\n",
      " wisdom\n",
      " great\n",
      " majesty\n",
      "\n",
      "Top predictions after the original repeated span:\n",
      " king\n",
      " wisdom\n",
      " wise\n",
      " old\n",
      " great\n",
      "\n",
      "Are the top 5 predictions the same after adjustment? False\n",
      "\n",
      "Top predictions after the adjusted repeated span:\n",
      " of\n",
      " and\n",
      " the\n",
      " his\n",
      " that\n",
      "\n",
      "Top predictions after the original repeated span:\n",
      " of\n",
      " and\n",
      " the\n",
      " his\n",
      " that\n",
      "\n",
      "Are the top 5 predictions the same after adjustment? True\n",
      "\n",
      "Top predictions after the adjusted repeated span:\n",
      " beauty\n",
      " happiness\n",
      " peace\n",
      " abundance\n",
      " prosperity\n",
      "\n",
      "Top predictions after the original repeated span:\n",
      " beauty\n",
      " happiness\n",
      " peace\n",
      " kindness\n",
      " wisdom\n",
      "\n",
      "Are the top 5 predictions the same after adjustment? False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Set up the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the GPT-2 XL tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-xl')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Create a long text with a repeated span\n",
    "text = (\n",
    "    \"Once upon a time in a land far, far away, there lived a wise old king. \"\n",
    "    \"He ruled his kingdom with justice and kindness, and all his subjects loved him dearly. \"\n",
    "    \"One day, a young traveler arrived at the kingdom. He had heard tales of the king's wisdom and sought his counsel. \"\n",
    "    \"The wise old king welcomed the traveler warmly. \"\n",
    "    \"He ruled his kingdom with justice and kindness, and all his subjects loved him dearly. \"  # Repeated span\n",
    "    \"The traveler was amazed by the prosperity and happiness of the people. \"\n",
    "    \"He decided to stay and learn from the king. \"\n",
    "    \"Years passed, and the traveler became a trusted advisor to the king. \"\n",
    ")\n",
    "\n",
    "# Tokenize the text\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt').to(device)\n",
    "\n",
    "# Convert input_ids to list for easy manipulation\n",
    "tokens = input_ids[0].tolist()\n",
    "\n",
    "# Decode tokens for verification\n",
    "decoded_tokens = [tokenizer.decode([token]) for token in tokens]\n",
    "\n",
    "# Manually identify the positions of the repeated spans\n",
    "# First occurrence\n",
    "t1_start = 19\n",
    "t1_end = 34  # Adjust if necessary\n",
    "\n",
    "# Second occurrence\n",
    "t2_start = 71\n",
    "t2_end = 86  # Adjust if necessary\n",
    "\n",
    "# Verify that the tokens in both spans are the same\n",
    "print(\"\\nFirst occurrence tokens:\")\n",
    "for i in range(t1_start, t1_end + 1):\n",
    "    print(f\"Token {i}: {tokens[i]} -> {repr(decoded_tokens[i])}\")\n",
    "\n",
    "print(\"\\nSecond occurrence tokens:\")\n",
    "for i in range(t2_start, t2_end + 1):\n",
    "    print(f\"Token {i}: {tokens[i]} -> {repr(decoded_tokens[i])}\")\n",
    "\n",
    "# Function to adjust hidden states\n",
    "def adjust_hidden_states(module, input, output):\n",
    "    # output is a tuple: (hidden_states, presents)\n",
    "    hidden_states = output[0]  # Extract the hidden states tensor\n",
    "    # Copy the hidden states from the first occurrence to the second occurrence\n",
    "    hidden_states[:, t2_start:t2_end+1, :] = hidden_states[:, t1_start:t1_end+1, :]\n",
    "    # Return the modified output as a tuple\n",
    "    return (hidden_states,) + output[1:]\n",
    "\n",
    "# Register the hook on the transformer blocks\n",
    "hooks = []\n",
    "for idx, block in enumerate(model.transformer.h):\n",
    "    hook = block.register_forward_hook(adjust_hidden_states)\n",
    "    hooks.append(hook)\n",
    "\n",
    "# Run the model with the hooks (adjusted)\n",
    "with torch.no_grad():\n",
    "    outputs_adjusted = model(input_ids)\n",
    "    logits_adjusted = outputs_adjusted.logits\n",
    "\n",
    "# Remove hooks after use\n",
    "for hook in hooks:\n",
    "    hook.remove()\n",
    "\n",
    "# Run the model without adjustments for comparison\n",
    "with torch.no_grad():\n",
    "    outputs_original = model(input_ids)\n",
    "    logits_original = outputs_original.logits\n",
    "\n",
    "# Compare the logits of the token following the repeated span\n",
    "for i in range(1, 10):\n",
    "    next_token_position = t2_end + i\n",
    "    logits_adjusted_next = logits_adjusted[:, next_token_position, :]\n",
    "    logits_original_next = logits_original[:, next_token_position, :]\n",
    "\n",
    "    # Get the top predicted tokens\n",
    "    top_k = 5\n",
    "    prob_original = torch.softmax(logits_original_next, dim=-1)\n",
    "    prob_adjusted = torch.softmax(logits_adjusted_next, dim=-1)\n",
    "\n",
    "    top_tokens_original = torch.topk(prob_original, top_k, dim=-1)\n",
    "    top_tokens_adjusted = torch.topk(prob_adjusted, top_k, dim=-1)\n",
    "\n",
    "    print(\"\\nTop predictions after the adjusted repeated span:\")\n",
    "    for idx in top_tokens_adjusted.indices[0]:\n",
    "        print(tokenizer.decode([idx.item()]))\n",
    "\n",
    "    print(\"\\nTop predictions after the original repeated span:\")\n",
    "    for idx in top_tokens_original.indices[0]:\n",
    "        print(tokenizer.decode([idx.item()]))\n",
    "\n",
    "    # Check if the predictions are the same\n",
    "    are_predictions_same = torch.equal(top_tokens_original.indices, top_tokens_adjusted.indices)\n",
    "    print(f\"\\nAre the top {top_k} predictions the same after adjustment? {are_predictions_same}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/phu.hoang/Documents/projects/copy_mech/test.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://10.127.30.121:8080/home/phu.hoang/Documents/projects/copy_mech/test.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautonotebook\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm \u001b[39mas\u001b[39;00m notebook_tqdm\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1)):\n",
    "    base_sent = preprocessing(base_sents[i])\n",
    "    phrase = preprocessing(phrases[i])\n",
    "    edited_sent = preprocessing(edited_sents[i])\n",
    "\n",
    "    prompt = f\"Base sentence: {base_sent}\\nPhrase to insert: {phrase}\\nEdited sentence: {edited_sent}\"\n",
    "\n",
    "    # Find the indices of the base sentence tokens in the edited sentence\n",
    "    result = find_base_sent(base_sent, prompt)\n",
    "    if not result:\n",
    "        continue  # Skip if matching fails\n",
    "    matching_indices_1st, matching_indices_2nd, input_ids, edited_encoded = result\n",
    "\n",
    "    # Function to adjust hidden states\n",
    "    def adjust_hidden_states(module, input, output):\n",
    "        print(\"adjust_hidden_states called\")\n",
    "        # output is a tuple: (hidden_states, presents)\n",
    "        hidden_states = output[0]  # Extract the hidden states tensor\n",
    "        # Copy the hidden states from the first occurrence to the second occurrence\n",
    "        hidden_states[:, matching_indices_2nd, :] = hidden_states[:, matching_indices_1st, :]\n",
    "        # Return the modified output as a tuple\n",
    "        return (hidden_states,) + output[1:]\n",
    "\n",
    "    print(f\"Using adjust_hidden_states function: {adjust_hidden_states}\")\n",
    "\n",
    "    # Register the hook on the transformer blocks\n",
    "    hooks = []\n",
    "    for idx, block in enumerate(model.transformer.h):\n",
    "        print(f\"Registering hook on layer {idx} with function {adjust_hidden_states}\")\n",
    "        hook = block.register_forward_hook(adjust_hidden_states)\n",
    "        hooks.append(hook)\n",
    "\n",
    "    # Run the model with the hooks (adjusted)\n",
    "    with torch.no_grad():\n",
    "        outputs_adjusted = model(input_ids)\n",
    "        logits_adjusted = outputs_adjusted.logits\n",
    "\n",
    "    # Remove hooks after use\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "    # Run the model without adjustments for comparison\n",
    "    with torch.no_grad():\n",
    "        outputs_original = model(input_ids)\n",
    "        logits_original = outputs_original.logits\n",
    "\n",
    "    # Rest of your code...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TinyLlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b5d1fbd04b46b8bf332a693fe3fd3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:  95%|#########4| 4.16G/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53628ec29af84162a3e5b6e18e7bc36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/129 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Replace with the model name or path\n",
    "model_name = \"TinyLlama/TinyLlama_v1.1\"  # Replace with \"phi-3-mini\" for the other model\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-21): 22 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phu.hoang/.conda/envs/copy_mech/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1600)\n",
       "    (wpe): Embedding(1024, 1600)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-47): 48 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1600, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Set up the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the GPT-2 XL tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-xl')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "jaccard = np.array([0.75, 0.80, 0.65, 0.90])\n",
    "acc = np.array([0.72, 0.85, 0.60, 0.88])\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "data = pd.DataFrame({\n",
    "    'Token': np.arange(len(jaccard)) + 1,  # Token IDs starting from 1\n",
    "    'Jaccard': jaccard,\n",
    "    'Acc': acc\n",
    "})\n",
    "\n",
    "# Melt the DataFrame to a long format suitable for Seaborn\n",
    "data_melted = data.melt(id_vars='Token', value_vars=['Jaccard', 'Acc'], \n",
    "                        var_name='Metric', value_name='Score')\n",
    "\n",
    "# Create a grouped bar plot\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.barplot(x='Token', y='Score', hue='Metric', data=data_melted)\n",
    "\n",
    "# Add a title and labels\n",
    "plt.title('Comparison of Jaccard and Acc Scores per Token')\n",
    "plt.xlabel('Token')\n",
    "plt.ylabel('Score')\n",
    "\n",
    "# Optionally, adjust the legend position\n",
    "plt.legend(title='Metric', loc='upper right')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "copy_mech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
